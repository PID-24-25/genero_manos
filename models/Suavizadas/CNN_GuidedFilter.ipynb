{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de género con imágenes de manos — Guided Filter\n",
    "\n",
    "## Este notebook implementa un modelo basado en redes neuronales convolucionales (CNN), utilizando un preprocesamiento con filtro guiado para suavizar las imágenes y realzar las características globales de la mano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parámetros de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE    = (224, 224)\n",
    "BATCH_SIZE  = 32\n",
    "RADIUS      = 10    # radio del filtro guiado\n",
    "EPS         = 0.01   # parámetro epsilon de suavizado\n",
    "\n",
    "csv_path   = \"../../dataset/HandInfo.csv\"\n",
    "image_root = \"../../dataset/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga del CSV y codificación de etiquetas de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df[\"label\"] = df[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "NUM_CLASSES = df[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalización Z-score para estandarizar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(image: np.ndarray) -> np.ndarray:\n",
    "    mean = image.mean()\n",
    "    std  = image.std()\n",
    "    return (image - mean) / (std + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocesamiento de imágenes con filtro guiado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_guided(path_bytes: bytes) -> np.ndarray:\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path).astype(np.float32)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    gf  = cv2.ximgproc.createGuidedFilter(guide=img, radius=RADIUS, eps=EPS)\n",
    "    low = gf.filter(img)\n",
    "    return z_score_normalization(low)\n",
    "\n",
    "def tf_preprocess(path, label):\n",
    "    out = tf.numpy_function(preprocess_image_guided, [path], tf.float32)\n",
    "    out.set_shape((*IMG_SIZE, 3))\n",
    "    return out, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creación de conjuntos de datos (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split: str):\n",
    "    folder = os.path.join(image_root, split)\n",
    "    files  = set(os.listdir(folder))\n",
    "    subdf  = df[df[\"imageName\"].isin(files)].sort_values(\"imageName\")\n",
    "    paths  = [os.path.join(folder, fn) for fn in subdf[\"imageName\"]]\n",
    "    labels = subdf[\"label\"].values\n",
    "    ds     = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds     = ds.map(tf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = create_dataset(\"train\")\n",
    "val_ds   = create_dataset(\"val\")\n",
    "test_ds  = create_dataset(\"test\")\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Validation dataset size:\", len(val_ds))\n",
    "print(\"Test dataset size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Definición de bloques residuales y arquitectura tipo ResNet-light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, downsample=False):\n",
    "    identity = x\n",
    "    stride   = 2 if downsample else 1\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if downsample or identity.shape[-1] != filters:\n",
    "        identity = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(identity)\n",
    "        identity = layers.BatchNormalization()(identity)\n",
    "\n",
    "    x = layers.Add()([x, identity])\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "def build_resnet(input_shape=(224,224,3), num_classes=2):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x   = layers.Conv2D(64, 7, strides=2, padding=\"same\", use_bias=False)(inp)\n",
    "    x   = layers.BatchNormalization()(x)\n",
    "    x   = layers.ReLU()(x)\n",
    "    x   = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    for _ in range(2):\n",
    "        x = residual_block(x, 64)\n",
    "    for i in range(3):\n",
    "        x = residual_block(x, 128, downsample=(i==0))\n",
    "    for i in range(4):\n",
    "        x = residual_block(x, 256, downsample=(i==0))\n",
    "    x   = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet(num_classes=NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.09, momentum=0.9, decay=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Callback personalizado para evaluar sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_ds):\n",
    "        super().__init__()\n",
    "        self.test_ds = test_ds\n",
    "        self.test_losses, self.test_accuracies = [], []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss, acc = self.model.evaluate(self.test_ds, verbose=0)\n",
    "        self.test_losses.append(loss)\n",
    "        self.test_accuracies.append(acc)\n",
    "        print(f\"  → Test loss: {loss:.4f} — Test acc: {acc:.4f}\")\n",
    "\n",
    "test_cb = TestCallback(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Scheduler de reducción de Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch == 3:\n",
    "        return lr * 0.7\n",
    "    return lr\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[lr_cb, test_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"guided_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Gráficas de precisión y pérdida: Train vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "train_acc = history.history[\"accuracy\"]\n",
    "test_acc  = test_cb.test_accuracies\n",
    "train_loss= history.history[\"loss\"]\n",
    "test_loss = test_cb.test_losses\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(epochs, train_acc, marker='o', color='blue', label='Train')\n",
    "ax1.plot(epochs, test_acc,  marker='s', color='red',  label='Test')\n",
    "ax1.set_title(\"Accuracy over epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(epochs, train_loss, marker='o', color='blue', label='Train')\n",
    "ax2.plot(epochs, test_loss,  marker='s', color='red',  label='Test')\n",
    "ax2.set_title(\"Loss over epochs\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
