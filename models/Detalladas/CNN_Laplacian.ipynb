{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617bd839",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n de g√©nero con im√°genes de manos ‚Äî Filtro Laplaciano\n",
    "\n",
    "# En este notebook se implementa una red neuronal convolucional tipo ResNet-light para clasificar el g√©nero a partir de im√°genes de manos. Se utiliza un preprocesamiento basado en el operador Laplaciano, que resalta los contornos y detalles locales de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b97ef",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3e5f4",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n de par√°metros generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE    = (224, 224)\n",
    "BATCH_SIZE  = 32\n",
    "\n",
    "csv_path   = \"../../dataset/HandInfo.csv\"\n",
    "image_root = \"../../dataset/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed4e9a",
   "metadata": {},
   "source": [
    "## 3. Carga de etiquetas y mapeo de g√©nero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df[\"label\"] = df[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "NUM_CLASSES = df[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c572bc5",
   "metadata": {},
   "source": [
    "## 4. Funci√≥n de normalizaci√≥n Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ffb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(image: np.ndarray) -> np.ndarray:\n",
    "    mean = image.mean()\n",
    "    std  = image.std()\n",
    "    return (image - mean) / (std + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac14d7",
   "metadata": {},
   "source": [
    "## 5. Preprocesamiento con el filtro Laplaciano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path_bytes: bytes) -> np.ndarray:\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE).astype(np.float32)\n",
    "    img = cv2.Laplacian(img, cv2.CV_32F)\n",
    "    return z_score_normalization(img)\n",
    "\n",
    "def tf_preprocess(path, label):\n",
    "    img = tf.numpy_function(preprocess_image, [path], tf.float32)\n",
    "    img.set_shape((*IMG_SIZE, 3))\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7523bf2",
   "metadata": {},
   "source": [
    "## 6. Creaci√≥n de datasets (entrenamiento, validaci√≥n, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split_name: str):\n",
    "    folder = os.path.join(image_root, split_name)\n",
    "    files  = set(os.listdir(folder))\n",
    "    subdf  = df[df[\"imageName\"].isin(files)].sort_values(\"imageName\")\n",
    "    paths  = [os.path.join(folder, fn) for fn in subdf[\"imageName\"]]\n",
    "    labels = subdf[\"label\"].values\n",
    "    ds     = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds     = ds.map(tf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split_name == \"train\":\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = create_dataset(\"train\")\n",
    "val_ds   = create_dataset(\"val\")\n",
    "test_ds  = create_dataset(\"test\")\n",
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Validation samples: {len(val_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bec29",
   "metadata": {},
   "source": [
    "## 7. Definici√≥n de bloques residuales y red tipo ResNet-light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcf5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, downsample=False):\n",
    "    identity = x\n",
    "    stride   = 2 if downsample else 1\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if downsample or identity.shape[-1] != filters:\n",
    "        identity = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(identity)\n",
    "        identity = layers.BatchNormalization()(identity)\n",
    "\n",
    "    x = layers.Add()([x, identity])\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "def build_resnet(input_shape=(224,224,3), num_classes=2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x      = layers.Conv2D(64, 7, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
    "    x      = layers.BatchNormalization()(x)\n",
    "    x      = layers.ReLU()(x)\n",
    "    x      = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    for _ in range(2):\n",
    "        x = residual_block(x, 64)\n",
    "    for i in range(3):\n",
    "        x = residual_block(x, 128, downsample=(i==0))\n",
    "    for i in range(4):\n",
    "        x = residual_block(x, 256, downsample=(i==0))\n",
    "    x      = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs= layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63166b45",
   "metadata": {},
   "source": [
    "## 8. Compilaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d828cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.09\n",
    "optimizer  = SGD(learning_rate=initial_lr, momentum=0.9, decay=0.001)\n",
    "model      = build_resnet(num_classes=NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198ec5b",
   "metadata": {},
   "source": [
    "## 9. Callback personalizado para evaluar sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05482fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_dataset):\n",
    "        super().__init__()\n",
    "        self.test_ds = test_dataset\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss, acc = self.model.evaluate(self.test_ds, verbose=0)\n",
    "        self.test_losses.append(loss)\n",
    "        self.test_accuracies.append(acc)\n",
    "        print(f\"  ‚Üí Test loss: {loss:.4f} ‚Äî Test acc: {acc:.4f}\")\n",
    "\n",
    "test_cb = TestMetricsCallback(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82595c4a",
   "metadata": {},
   "source": [
    "## 10. Scheduler para modificar el learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch == 3:  # reduce a epoch 4\n",
    "        return lr * 0.7\n",
    "    return lr\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d17b80",
   "metadata": {},
   "source": [
    "## 11. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ae635",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[lr_cb, test_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4ad93",
   "metadata": {},
   "source": [
    "## 12. Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"laplacian_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd61350",
   "metadata": {},
   "source": [
    "## 13. Visualizaci√≥n de m√©tricas: precisi√≥n y p√©rdida por √©poca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "train_acc = history.history[\"accuracy\"]\n",
    "test_acc  = test_cb.test_accuracies\n",
    "train_loss= history.history[\"loss\"]\n",
    "test_loss = test_cb.test_losses\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(epochs, train_acc, marker='o', color='blue', label='Train')\n",
    "ax1.plot(epochs, test_acc,  marker='o', color='red', label='Test')\n",
    "ax1.set_title('Accuracy over epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(epochs, train_loss, marker='o', color='blue', label='Train')\n",
    "ax2.plot(epochs, test_loss,  marker='o', color='red', label='Test')\n",
    "ax2.set_title('Loss over epochs')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3d4f8",
   "metadata": {},
   "source": [
    "## üîÑ Preprocesamiento con Laplacian (actualizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbdc40",
   "metadata": {},
   "source": [
    "# Aplicamos el filtro Laplaciano (con ksize=3) para extraer detalles de alta frecuencia y normalizamos con Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path_bytes: bytes) -> np.ndarray:\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path).astype(np.float32)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    lap = cv2.Laplacian(img, cv2.CV_32F, ksize=3)\n",
    "    return z_score_normalization(lap)\n",
    "\n",
    "def tf_preprocess(path, label):\n",
    "    img = tf.numpy_function(preprocess_image, [path], tf.float32)\n",
    "    img.set_shape((*IMG_SIZE, 3))\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fdcde",
   "metadata": {},
   "source": [
    "## Construimos los datasets nuevamente con el nuevo preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(\"train\")\n",
    "val_ds   = create_dataset(\"val\")\n",
    "test_ds  = create_dataset(\"test\")\n",
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Validation samples: {len(val_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5abeb",
   "metadata": {},
   "source": [
    "## A√±adimos regularizaci√≥n L2 a las capas convolucionales y Dropout antes de la capa final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd10fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def residual_block(x, filters, downsample=False):\n",
    "    reg = regularizers.l2(1e-4)\n",
    "    identity = x\n",
    "    stride   = 2 if downsample else 1\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\",\n",
    "                      use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, strides=1, padding=\"same\",\n",
    "                      use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if downsample or identity.shape[-1] != filters:\n",
    "        identity = layers.Conv2D(filters, 1, strides=stride,\n",
    "                                 use_bias=False, kernel_regularizer=reg)(identity)\n",
    "        identity = layers.BatchNormalization()(identity)\n",
    "\n",
    "    x = layers.Add()([x, identity])\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "def build_resnet(input_shape=(224,224,3), num_classes=2):\n",
    "    reg = regularizers.l2(1e-4)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x      = layers.Conv2D(64, 7, strides=2, padding=\"same\",\n",
    "                           use_bias=False, kernel_regularizer=reg)(inputs)\n",
    "    x      = layers.BatchNormalization()(x)\n",
    "    x      = layers.ReLU()(x)\n",
    "    x      = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    for _ in range(2):\n",
    "        x = residual_block(x, 64)\n",
    "    for i in range(3):\n",
    "        x = residual_block(x, 128, downsample=(i==0))\n",
    "    for i in range(4):\n",
    "        x = residual_block(x, 256, downsample=(i==0))\n",
    "\n",
    "    x      = layers.GlobalAveragePooling2D()(x)\n",
    "    x      = layers.Dropout(0.5)(x)\n",
    "    outputs= layers.Dense(num_classes, activation=\"softmax\",\n",
    "                          kernel_regularizer=reg)(x)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851e75b",
   "metadata": {},
   "source": [
    "## Usamos una tasa de aprendizaje inicial m√°s baja, adecuada para detalles finos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.03\n",
    "optimizer  = SGD(learning_rate=initial_lr, momentum=0.9)\n",
    "model      = build_resnet(num_classes=NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939502f",
   "metadata": {},
   "source": [
    "## Scheduler para disminuir el LR en la 4¬™ √©poca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da82a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch == 3:\n",
    "        return lr * 0.5\n",
    "    return lr\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0feb707",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2308d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[lr_cb, test_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cdd47a",
   "metadata": {},
   "source": [
    "## Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"laplacian_model_regularized.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed0ff49",
   "metadata": {},
   "source": [
    "## Visualizaci√≥n de m√©tricas: precisi√≥n y p√©rdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e841a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "train_acc = history.history[\"accuracy\"]\n",
    "test_acc  = test_cb.test_accuracies\n",
    "train_loss= history.history[\"loss\"]\n",
    "test_loss = test_cb.test_losses\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(epochs, train_acc, marker='o', color='blue', label='Train')\n",
    "ax1.plot(epochs, test_acc,  marker='s', color='red', label='Test')\n",
    "ax1.set_title('Accuracy over epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(epochs, train_loss, marker='o', color='blue', label='Train')\n",
    "ax2.plot(epochs, test_loss,  marker='s', color='red', label='Test')\n",
    "ax2.set_title('Loss over epochs')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
