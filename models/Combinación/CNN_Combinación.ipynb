{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420617d7",
   "metadata": {},
   "source": [
    "## Clasificación de género con imágenes de manos — Modelo de Fusión\n",
    "\n",
    "## Este notebook combina dos modelos previamente entrenados con diferentes preprocesamientos (GaussianBlur y Sobel) para mejorar la clasificación de género mediante una arquitectura de doble entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45ac1b",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d97ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f5708",
   "metadata": {},
   "source": [
    "## 2. Configuración de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "CSV_PATH   = \"../../dataset/HandInfo.csv\"\n",
    "IMAGE_ROOT = \"../../dataset/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0972c5",
   "metadata": {},
   "source": [
    "## 3. Carga del CSV y codificación de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61925f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"label\"] = df[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "NUM_CLASSES = df[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d8515",
   "metadata": {},
   "source": [
    "## 4. Función de normalización Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbc949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(image: np.ndarray) -> np.ndarray:\n",
    "    mean = image.mean()\n",
    "    std  = image.std()\n",
    "    return (image - mean) / (std + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacff85",
   "metadata": {},
   "source": [
    "## 5. Funciones de preprocesamiento: GaussianBlur y Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gaussian(path_bytes: bytes) -> np.ndarray:\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE).astype(np.float32)\n",
    "    img = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "    return z_score_normalization(img)\n",
    "\n",
    "def preprocess_sobel(path_bytes: bytes) -> np.ndarray:\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    gx  = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy  = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    img = np.sqrt(gx**2 + gy**2)\n",
    "    return z_score_normalization(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7165042",
   "metadata": {},
   "source": [
    "# 6. Creación de datasets para ambas ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_preprocess(fn):\n",
    "    def _fn(path, label):\n",
    "        img = tf.numpy_function(fn, [path], tf.float32)\n",
    "        img.set_shape((*IMG_SIZE, 3))\n",
    "        return img, label\n",
    "    return _fn\n",
    "\n",
    "def create_ds(split, fn):\n",
    "    folder = os.path.join(IMAGE_ROOT, split)\n",
    "    files  = set(os.listdir(folder))\n",
    "    subdf  = df[df[\"imageName\"].isin(files)].sort_values(\"imageName\")\n",
    "    paths  = [os.path.join(folder,n) for n in subdf[\"imageName\"]]\n",
    "    labels = subdf[\"label\"].values\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(make_tf_preprocess(fn), tf.data.AUTOTUNE)\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "g_tr = create_ds(\"train\", preprocess_gaussian)\n",
    "g_va = create_ds(\"val\",   preprocess_gaussian)\n",
    "g_te = create_ds(\"test\",  preprocess_gaussian)\n",
    "s_tr = create_ds(\"train\", preprocess_sobel)\n",
    "s_va = create_ds(\"val\",   preprocess_sobel)\n",
    "s_te = create_ds(\"test\",  preprocess_sobel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67d505",
   "metadata": {},
   "source": [
    "## 7. Fusionar datasets de ambas ramas con `tf.data.Dataset.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f36303",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((g_tr, s_tr)) \\\n",
    "    .map(lambda g, s: ((g[0], s[0]), g[1]), tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.zip((g_va, s_va)) \\\n",
    "    .map(lambda g, s: ((g[0], s[0]), g[1]), tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.zip((g_te, s_te)) \\\n",
    "    .map(lambda g, s: ((g[0], s[0]), g[1]), tf.data.AUTOTUNE)\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Validation dataset size:\", len(val_ds))\n",
    "print(\"Test dataset size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75333d91",
   "metadata": {},
   "source": [
    "## 8. Carga de modelos preentrenados y extracción de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba49662",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_model = load_model(\"../Suavizadas/gaussian_model.h5\")\n",
    "sobel_model = load_model(\"../Detalladas/sobel_model.h5\")\n",
    "\n",
    "gauss_model.trainable = False\n",
    "sobel_model.trainable = False\n",
    "\n",
    "gap_g = next(l for l in gauss_model.layers if isinstance(l, GlobalAveragePooling2D))\n",
    "gap_s = next(l for l in sobel_model.layers if isinstance(l, GlobalAveragePooling2D))\n",
    "\n",
    "feat_g = Model(gauss_model.input, gap_g.output)\n",
    "feat_s = Model(sobel_model.input, gap_s.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2dbf6",
   "metadata": {},
   "source": [
    "## 9. Definición del modelo de fusión con dos ramas de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_g = layers.Input((*IMG_SIZE, 3), name=\"in_gauss\")\n",
    "inp_s = layers.Input((*IMG_SIZE, 3), name=\"in_sobel\")\n",
    "\n",
    "emb_g = feat_g(inp_g)\n",
    "emb_s = feat_s(inp_s)\n",
    "\n",
    "x = layers.Concatenate()([emb_g, emb_s])\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "out = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "fusion = Model([inp_g, inp_s], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871303b0",
   "metadata": {},
   "source": [
    "## 10. Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b19dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "fusion.compile(\n",
    "    optimizer=opt,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1add35a",
   "metadata": {},
   "source": [
    "## 11. Callbacks para reducción de LR y evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97fbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.8,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "class TestCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_ds):\n",
    "        super().__init__()\n",
    "        self.test_ds = test_ds\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss, acc = self.model.evaluate(self.test_ds, verbose=0)\n",
    "        self.test_losses.append(loss)\n",
    "        self.test_accuracies.append(acc)\n",
    "        print(f\"  → Test loss: {loss:.4f} — Test acc: {acc:.4f}\")\n",
    "\n",
    "test_cb = TestCallback(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9d030",
   "metadata": {},
   "source": [
    "## 12. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107892e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fusion.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[lr_plateau, test_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83afa00",
   "metadata": {},
   "source": [
    "## 13. Guardar modelo fusionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion.save(\"fusion_gauss_sobel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b064a7",
   "metadata": {},
   "source": [
    "## 14. Visualización de resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs    = range(1, NUM_EPOCHS + 1)\n",
    "train_acc = history.history[\"accuracy\"]\n",
    "test_acc  = test_cb.test_accuracies\n",
    "train_loss= history.history[\"loss\"]\n",
    "test_loss = test_cb.test_losses\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(epochs, train_acc, marker='o', color='blue', label='Train')\n",
    "ax1.plot(epochs, test_acc,  marker='o', color='red', label='Test')\n",
    "ax1.set_title(\"Accuracy over epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(epochs, train_loss, marker='o', color='blue', label='Train')\n",
    "ax2.plot(epochs, test_loss,  marker='o', color='red', label='Test')\n",
    "ax2.set_title(\"Loss over epochs\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
