{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de género con imágenes de manos — Sin Preprocesamiento\n",
    "\n",
    "# En este notebook se entrena una red neuronal convolucional tipo ResNet-light para clasificar el género a partir de imágenes de manos sin aplicar filtros ni transformaciones adicionales.\n",
    "## Las imágenes se normalizan directamente en el rango [0, 1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuración general del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE    = (224, 224)\n",
    "BATCH_SIZE  = 32\n",
    "NUM_EPOCHS  = 5\n",
    "\n",
    "csv_path    = \"../../dataset/HandInfo.csv\"\n",
    "image_root  = \"../../dataset/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lectura del archivo CSV y codificación de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df[\"label\"] = df[\"gender\"].map({\"male\": 0, \"female\": 1})\n",
    "NUM_CLASSES = df[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento de imágenes sin filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw(path_bytes: bytes) -> np.ndarray:\n",
    "    \"\"\"Carga la imagen, redimensiona y normaliza a [0,1].\"\"\"\n",
    "    path = path_bytes.decode(\"utf-8\")\n",
    "    img  = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return np.zeros((*IMG_SIZE, 3), dtype=np.float32)\n",
    "    img = cv2.resize(img, IMG_SIZE).astype(np.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def tf_preprocess(path, label):\n",
    "    img = tf.numpy_function(preprocess_raw, [path], tf.float32)\n",
    "    img.set_shape((*IMG_SIZE, 3))\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construcción de conjuntos de datos con tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split: str):\n",
    "    folder = os.path.join(image_root, split)\n",
    "    files  = set(os.listdir(folder))\n",
    "    subdf  = df[df[\"imageName\"].isin(files)].sort_values(\"imageName\")\n",
    "    paths  = [os.path.join(folder, fn) for fn in subdf[\"imageName\"]]\n",
    "    labels = subdf[\"label\"].values\n",
    "    ds     = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds     = ds.map(tf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if split == \"train\":\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = create_dataset(\"train\")\n",
    "val_ds   = create_dataset(\"val\")\n",
    "test_ds  = create_dataset(\"test\")\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Validation dataset size:\", len(val_ds))\n",
    "print(\"Test dataset size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Arquitectura ResNet-light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, downsample=False):\n",
    "    identity = x\n",
    "    stride   = 2 if downsample else 1\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if downsample or identity.shape[-1] != filters:\n",
    "        identity = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(identity)\n",
    "        identity = layers.BatchNormalization()(identity)\n",
    "\n",
    "    x = layers.Add()([x, identity])\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "def build_resnet(input_shape=(224,224,3), num_classes=2):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x   = layers.Conv2D(64, 7, strides=2, padding=\"same\", use_bias=False)(inp)\n",
    "    x   = layers.BatchNormalization()(x)\n",
    "    x   = layers.ReLU()(x)\n",
    "    x   = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "    for _ in range(2):\n",
    "        x = residual_block(x, 64)\n",
    "    for i in range(3):\n",
    "        x = residual_block(x, 128, downsample=(i==0))\n",
    "    for i in range(4):\n",
    "        x = residual_block(x, 256, downsample=(i==0))\n",
    "    x   = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet(num_classes=NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.09, momentum=0.9, decay=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Callback para evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_ds):\n",
    "        super().__init__()\n",
    "        self.test_ds = test_ds\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss, acc = self.model.evaluate(self.test_ds, verbose=0)\n",
    "        self.test_losses.append(loss)\n",
    "        self.test_accuracies.append(acc)\n",
    "        print(f\"  → Test loss: {loss:.4f} — Test acc: {acc:.4f}\")\n",
    "\n",
    "test_cb = TestCallback(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Scheduler para reducir el learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch == 3:\n",
    "        return lr * 0.7\n",
    "    return lr\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[lr_cb, test_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Guardado del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"simple_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualización de métricas de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = range(1, NUM_EPOCHS + 1)\n",
    "train_acc  = history.history[\"accuracy\"]\n",
    "test_acc   = test_cb.test_accuracies\n",
    "train_loss = history.history[\"loss\"]\n",
    "test_loss  = test_cb.test_losses\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(epochs, train_acc, marker='o', color='blue', label='Train')\n",
    "ax1.plot(epochs, test_acc,  marker='o', color='red', label='Test')\n",
    "ax1.set_title(\"Accuracy over epochs\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(epochs, train_loss, marker='o', color='blue', label='Train')\n",
    "ax2.plot(epochs, test_loss,  marker='o', color='red', label='Test')\n",
    "ax2.set_title(\"Loss over epochs\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
